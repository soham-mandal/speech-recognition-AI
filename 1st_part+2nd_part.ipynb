{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voice Authentication Model\n",
    "============\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this jupyter notebook we will extract features from the voice input (.wav) using MFCC followed by training and evaluation of developed GMM model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data consists of 4 speakers who generate 13 (now 10 training + 3 testing) (later 13 training + 1 user recording) wav files for telephone and august."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I) Visualizing Data\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import wave, sys\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "II) Feature Extraction & Model Training\n",
    "-----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install python_speech_features\n",
    "#!pip install sklearn\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import python_speech_features as mfcc\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper functions to calculate Deltas and Extract Features\n",
    "\n",
    "def calculate_delta(array):\n",
    "    \"\"\"Calculate and returns the delta of given feature vector matrix\"\"\"\n",
    "\n",
    "    rows,cols = array.shape\n",
    "    deltas = np.zeros((rows,20))\n",
    "    N = 2\n",
    "    for i in range(rows):\n",
    "        index = []\n",
    "        j = 1\n",
    "        while j <= N:\n",
    "            if i-j < 0:                 \n",
    "                first = 0             \n",
    "            else:                 \n",
    "                first = i-j             \n",
    "            \n",
    "            if i+j > rows-1:\n",
    "                second = rows-1\n",
    "            else:\n",
    "                second = i+j \n",
    "            \n",
    "            index.append((second,first))\n",
    "            j+=1\n",
    "        deltas[i] = ( array[index[0][0]]-array[index[0][1]] + (2 * (array[index[1][0]]-array[index[1][1]])) ) / 10\n",
    "    return deltas\n",
    "\n",
    "def extract_features(audio,rate):\n",
    "    \"\"\"extract 20 dim mfcc features from an audio, performs CMS and combines \n",
    "    delta to make it 40 dim feature vector\"\"\"    \n",
    "    \n",
    "    mfcc_feat = mfcc.mfcc(audio,rate, 0.025, 0.01,20,appendEnergy = True)    \n",
    "    mfcc_feat = preprocessing.scale(mfcc_feat)\n",
    "    delta = calculate_delta(mfcc_feat)\n",
    "    combined = np.hstack((mfcc_feat,delta)) \n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker1_digit_1\\wav\\Speaker1_digit_1_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker1_digit_1\\wav\\Speaker1_digit_1_1.wav\n",
      "Speaker1_digit_1\\wav\\Speaker1_digit_1_2.wav\n",
      "Speaker1_digit_1\\wav\\Speaker1_digit_1_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker1_digit_1\\wav\\Speaker1_digit_1_4.wav\n",
      "Speaker1_digit_1\\wav\\Speaker1_digit_1_5.wav\n",
      "Speaker1_digit_1\\wav\\Speaker1_digit_1_6.wav\n",
      "Speaker1_digit_1\\wav\\Speaker1_digit_1_7.wav\n",
      "Speaker1_digit_1\\wav\\Speaker1_digit_1_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker1_digit_1\\wav\\Speaker1_digit_1_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ modeling completed for speaker: Speaker1_digit_1.gmm  with data point =  (1272, 40)\n",
      "Speaker1_digit_1\\wav\\Speaker1_digit_1_10.wav\n",
      "Speaker1_digit_1\\wav\\Speaker1_digit_1_11.wav\n",
      "Speaker1_digit_1\\wav\\Speaker1_digit_1_12.wav\n",
      "Speaker1_digit_2\\wav\\Speaker1_digit_2_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker1_digit_2\\wav\\Speaker1_digit_2_1.wav\n",
      "Speaker1_digit_2\\wav\\Speaker1_digit_2_2.wav\n",
      "Speaker1_digit_2\\wav\\Speaker1_digit_2_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker1_digit_2\\wav\\Speaker1_digit_2_4.wav\n",
      "Speaker1_digit_2\\wav\\Speaker1_digit_2_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker1_digit_2\\wav\\Speaker1_digit_2_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ modeling completed for speaker: Speaker1_digit_2.gmm  with data point =  (1556, 40)\n",
      "Speaker1_digit_2\\wav\\Speaker1_digit_2_7.wav\n",
      "Speaker1_digit_2\\wav\\Speaker1_digit_2_8.wav\n",
      "Speaker1_digit_2\\wav\\Speaker1_digit_2_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker1_digit_2\\wav\\Speaker1_digit_2_10.wav\n",
      "Speaker1_digit_2\\wav\\Speaker1_digit_2_11.wav\n",
      "Speaker1_digit_2\\wav\\Speaker1_digit_2_12.wav\n",
      "Speaker2_digit_1\\wav\\Speaker2_digit_1_0.wav\n",
      "Speaker2_digit_1\\wav\\Speaker2_digit_1_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker2_digit_1\\wav\\Speaker2_digit_1_2.wav\n",
      "Speaker2_digit_1\\wav\\Speaker2_digit_1_3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ modeling completed for speaker: Speaker2_digit_1.gmm  with data point =  (1873, 40)\n",
      "Speaker2_digit_1\\wav\\Speaker2_digit_1_4.wav\n",
      "Speaker2_digit_1\\wav\\Speaker2_digit_1_5.wav\n",
      "Speaker2_digit_1\\wav\\Speaker2_digit_1_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker2_digit_1\\wav\\Speaker2_digit_1_7.wav\n",
      "Speaker2_digit_1\\wav\\Speaker2_digit_1_8.wav\n",
      "Speaker2_digit_1\\wav\\Speaker2_digit_1_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker2_digit_1\\wav\\Speaker2_digit_1_10.wav\n",
      "Speaker2_digit_2\\wav\\Speaker2_digit_2_0.wav\n",
      "Speaker2_digit_2\\wav\\Speaker2_digit_2_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker2_digit_2\\wav\\Speaker2_digit_2_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ modeling completed for speaker: Speaker2_digit_2.gmm  with data point =  (2999, 40)\n",
      "Speaker2_digit_2\\wav\\Speaker2_digit_2_3.wav\n",
      "Speaker2_digit_2\\wav\\Speaker2_digit_2_4.wav\n",
      "Speaker2_digit_2\\wav\\Speaker2_digit_2_5.wav\n",
      "Speaker2_digit_2\\wav\\Speaker2_digit_2_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker2_digit_2\\wav\\Speaker2_digit_2_7.wav\n",
      "Speaker2_digit_2\\wav\\Speaker2_digit_2_8.wav\n",
      "Speaker2_digit_2\\wav\\Speaker2_digit_2_9.wav\n",
      "Speaker2_digit_2\\wav\\Speaker2_digit_2_10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker3_digit_1\\wav\\Speaker3_digit_1_0.wav\n",
      "Speaker3_digit_1\\wav\\Speaker3_digit_1_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ modeling completed for speaker: Speaker3_digit_1.gmm  with data point =  (2787, 40)\n",
      "Speaker3_digit_1\\wav\\Speaker3_digit_1_2.wav\n",
      "Speaker3_digit_1\\wav\\Speaker3_digit_1_3.wav\n",
      "Speaker3_digit_1\\wav\\Speaker3_digit_1_4.wav\n",
      "Speaker3_digit_1\\wav\\Speaker3_digit_1_5.wav\n",
      "Speaker3_digit_1\\wav\\Speaker3_digit_1_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker3_digit_1\\wav\\Speaker3_digit_1_7.wav\n",
      "Speaker3_digit_1\\wav\\Speaker3_digit_1_8.wav\n",
      "Speaker3_digit_1\\wav\\Speaker3_digit_1_9.wav\n",
      "Speaker3_digit_1\\wav\\Speaker3_digit_1_10.wav\n",
      "Speaker3_digit_1\\wav\\Speaker3_digit_1_11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ modeling completed for speaker: Speaker3_digit_1.gmm  with data point =  (2190, 40)\n",
      "Speaker3_digit_1\\wav\\Speaker3_digit_1_12.wav\n",
      "Speaker3_digit_2\\wav\\Speaker3_digit_2_0.wav\n",
      "Speaker3_digit_2\\wav\\Speaker3_digit_2_1.wav\n",
      "Speaker3_digit_2\\wav\\Speaker3_digit_2_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker3_digit_2\\wav\\Speaker3_digit_2_3.wav\n",
      "Speaker3_digit_2\\wav\\Speaker3_digit_2_4.wav\n",
      "Speaker3_digit_2\\wav\\Speaker3_digit_2_5.wav\n",
      "Speaker3_digit_2\\wav\\Speaker3_digit_2_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker3_digit_2\\wav\\Speaker3_digit_2_7.wav\n",
      "Speaker3_digit_2\\wav\\Speaker3_digit_2_8.wav\n",
      "+ modeling completed for speaker: Speaker3_digit_2.gmm  with data point =  (2341, 40)\n",
      "Speaker3_digit_2\\wav\\Speaker3_digit_2_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker3_digit_2\\wav\\Speaker3_digit_2_10.wav\n",
      "Speaker3_digit_2\\wav\\Speaker3_digit_2_11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker3_digit_2\\wav\\Speaker3_digit_2_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker4_digit_1\\wav\\Speaker4_digit_1_0.wav\n",
      "Speaker4_digit_1\\wav\\Speaker4_digit_1_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker4_digit_1\\wav\\Speaker4_digit_1_2.wav\n",
      "Speaker4_digit_1\\wav\\Speaker4_digit_1_3.wav\n",
      "Speaker4_digit_1\\wav\\Speaker4_digit_1_4.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker4_digit_1\\wav\\Speaker4_digit_1_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ modeling completed for speaker: Speaker4_digit_1.gmm  with data point =  (2712, 40)\n",
      "Speaker4_digit_1\\wav\\Speaker4_digit_1_6.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker4_digit_1\\wav\\Speaker4_digit_1_7.wav\n",
      "Speaker4_digit_1\\wav\\Speaker4_digit_1_8.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker4_digit_1\\wav\\Speaker4_digit_1_9.wav\n",
      "Speaker4_digit_1\\wav\\Speaker4_digit_1_10.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker4_digit_1\\wav\\Speaker4_digit_1_11.wav\n",
      "Speaker4_digit_1\\wav\\Speaker4_digit_1_12.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker4_digit_2\\wav\\Speaker4_digit_2_0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker4_digit_2\\wav\\Speaker4_digit_2_1.wav\n",
      "Speaker4_digit_2\\wav\\Speaker4_digit_2_2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ modeling completed for speaker: Speaker4_digit_2.gmm  with data point =  (2908, 40)\n",
      "Speaker4_digit_2\\wav\\Speaker4_digit_2_3.wav\n",
      "Speaker4_digit_2\\wav\\Speaker4_digit_2_4.wav\n",
      "Speaker4_digit_2\\wav\\Speaker4_digit_2_5.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker4_digit_2\\wav\\Speaker4_digit_2_6.wav\n",
      "Speaker4_digit_2\\wav\\Speaker4_digit_2_7.wav\n",
      "Speaker4_digit_2\\wav\\Speaker4_digit_2_8.wav\n",
      "Speaker4_digit_2\\wav\\Speaker4_digit_2_9.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker4_digit_2\\wav\\Speaker4_digit_2_10.wav\n",
      "Speaker4_digit_2\\wav\\Speaker4_digit_2_11.wav\n",
      "Speaker4_digit_2\\wav\\Speaker4_digit_2_12.wav\n",
      "+ modeling completed for speaker: Speaker4_digit_2.gmm  with data point =  (2700, 40)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import read\n",
    "from sklearn import mixture\n",
    "#from sklearn.mixture import GMM \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#path to training data\n",
    "source   = \"letters\\\\\"   \n",
    "\n",
    "#path where training speakers will be saved\n",
    "dest = \"models\\\\\"\n",
    "train_file = \"tr.txt\"        \n",
    "file_paths = open(train_file,'r')\n",
    "\n",
    "count = 1\n",
    "# Extracting features for each digit data provided by speaker \n",
    "features = np.asarray(())\n",
    "for path in file_paths:    \n",
    "    path = path.strip()   \n",
    "    print(path)\n",
    "    \n",
    "    # read the audio\n",
    "    sr,audio = read(source + path)\n",
    "    \n",
    "    # extract 40 dimensional MFCC & delta MFCC features\n",
    "    vector   = extract_features(audio,sr)\n",
    "    \n",
    "    if features.size == 0:\n",
    "        features = vector\n",
    "    else:\n",
    "        features = np.vstack((features, vector))\n",
    "    # when features of training files of each digit for a given speaker are concatenated, model training is done\n",
    "    if count == 10:   \n",
    "        gmm = mixture.GaussianMixture(n_components = 16, max_iter = 200, covariance_type='diag',n_init = 3) \n",
    "        #gmm = GMM(n_components = 16, n_iter = 200, covariance_type='diag',n_init = 3)\n",
    "        gmm.fit(features)\n",
    "        \n",
    "        # dumping the trained gaussian model\n",
    "        picklefile = path.split(\"\\\\\")[0]+\".gmm\"\n",
    "        pickle.dump(gmm,open(dest + picklefile,'wb'))\n",
    "        print('+ modeling completed for speaker:',picklefile,\" with data point = \",features.shape)    \n",
    "        features = np.asarray(())\n",
    "        count = 0\n",
    "    count = count + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "III) Voice Input\n",
    "-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* recording\n",
      "* done recording\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import sys\n",
    "\n",
    "chunk = 1024\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 44100\n",
    "RECORD_SECONDS = 3\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "stream = p.open(format = FORMAT,\n",
    "                channels = CHANNELS,\n",
    "                rate = RATE,\n",
    "                input = True,\n",
    "                frames_per_buffer = chunk)\n",
    "\n",
    "print (\"* recording\")\n",
    "all = []\n",
    "for i in range(0, int(RATE / chunk) * RECORD_SECONDS):\n",
    "    data = stream.read(chunk, exception_on_overflow = False)\n",
    "    all.append(data)\n",
    "print (\"* done recording\")\n",
    "\n",
    "stream.close()\n",
    "p.terminate()\n",
    "\n",
    "sound_file = wave.open(\"letters\\\\authentication\\\\myrecording.wav\", 'wb')\n",
    "sound_file.setnchannels(1)\n",
    "sound_file.setsampwidth(p.get_sample_size(pyaudio.paInt16))\n",
    "sound_file.setframerate(44100)\n",
    "sound_file.writeframes(b''.join(all))\n",
    "sound_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IV) Model Testing\n",
    "-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models\\\\Speaker1_digit_1.gmm',\n",
       " 'models\\\\Speaker1_digit_2.gmm',\n",
       " 'models\\\\Speaker2_digit_1.gmm',\n",
       " 'models\\\\Speaker2_digit_2.gmm',\n",
       " 'models\\\\Speaker3_digit_1.gmm',\n",
       " 'models\\\\Speaker3_digit_2.gmm',\n",
       " 'models\\\\Speaker4_digit_1.gmm',\n",
       " 'models\\\\Speaker4_digit_2.gmm']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time, os\n",
    "\n",
    "#path to training data\n",
    "source   = \"letters\\\\\"   \n",
    "models_dir = \"models\\\\\"\n",
    "test_file = \"tst.txt\"        \n",
    "file_paths = open(test_file,'r')\n",
    "\n",
    "gmm_files = [os.path.join(models_dir,fname) for fname in os.listdir(models_dir) if fname.endswith('.gmm')]\n",
    "\n",
    "gmm_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[GaussianMixture(covariance_type='diag', max_iter=200, n_components=16, n_init=3),\n",
       " GaussianMixture(covariance_type='diag', max_iter=200, n_components=16, n_init=3),\n",
       " GaussianMixture(covariance_type='diag', max_iter=200, n_components=16, n_init=3),\n",
       " GaussianMixture(covariance_type='diag', max_iter=200, n_components=16, n_init=3),\n",
       " GaussianMixture(covariance_type='diag', max_iter=200, n_components=16, n_init=3),\n",
       " GaussianMixture(covariance_type='diag', max_iter=200, n_components=16, n_init=3),\n",
       " GaussianMixture(covariance_type='diag', max_iter=200, n_components=16, n_init=3),\n",
       " GaussianMixture(covariance_type='diag', max_iter=200, n_components=16, n_init=3)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the Gaussian Models\n",
    "models    = [pickle.load(open(fname,'rb')) for fname in gmm_files]\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Speaker1_digit_1',\n",
       " 'Speaker1_digit_2',\n",
       " 'Speaker2_digit_1',\n",
       " 'Speaker2_digit_2',\n",
       " 'Speaker3_digit_1',\n",
       " 'Speaker3_digit_2',\n",
       " 'Speaker4_digit_1',\n",
       " 'Speaker4_digit_2']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speakers_digit   = [fname.split(\"\\\\\")[-1].split(\".gmm\")[0] for fname in gmm_files]\n",
    "speakers_digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "authentication\\myrecording.wav\n",
      "\tSpeaker & Digit detected as -  Speaker3_digit_2\n",
      "speaker is m and term is august\n"
     ]
    }
   ],
   "source": [
    "# Read the test directory and get the list of test audio files \n",
    "path_predicted_dict = dict()\n",
    "\n",
    "for path in file_paths:   \n",
    "    \n",
    "    path = path.strip()   \n",
    "    print(path)\n",
    "    sr,audio = read(source + path)\n",
    "    vector   = extract_features(audio,sr)\n",
    "    \n",
    "    log_likelihood = np.zeros(len(models)) \n",
    "    \n",
    "    for i in range(len(models)):\n",
    "        gmm    = models[i]  #checking with each model one by one\n",
    "        scores = np.array(gmm.score(vector))\n",
    "        log_likelihood[i] = scores.sum()\n",
    "    \n",
    "    winner = np.argmax(log_likelihood)\n",
    "    print(\"\\tSpeaker & Digit detected as - \", speakers_digit[winner])\n",
    "    path_predicted_dict[path] = speakers_digit[winner]\n",
    "\n",
    "    if (speakers_digit[winner] == 'Speaker1_digit_1'):\n",
    "        print('speaker is s and term is telephone')\n",
    "        user = 1\n",
    "        break\n",
    "    elif (speakers_digit[winner] == 'Speaker1_digit_2'):\n",
    "        print('speaker is s and term is august')\n",
    "        user = 1\n",
    "        break\n",
    "    elif (speakers_digit[winner] == 'Speaker2_digit_1'):\n",
    "        print('speaker is p and term is telephone')\n",
    "        user = 2\n",
    "        break\n",
    "    elif (speakers_digit[winner] == 'Speaker2_digit_2'):\n",
    "        print('speaker is p and term is august')\n",
    "        user = 2\n",
    "        break\n",
    "    elif (speakers_digit[winner] == 'Speaker3_digit_1'):\n",
    "        print('speaker is m and term is telephone')\n",
    "        user = 3\n",
    "        break\n",
    "    elif (speakers_digit[winner] == 'Speaker3_digit_2'):\n",
    "        print('speaker is m and term is august')\n",
    "        user = 3\n",
    "        break\n",
    "    elif (speakers_digit[winner] == 'Speaker4_digit_1'):\n",
    "        print('speaker is l and term is telephone')\n",
    "        user = 4\n",
    "        break\n",
    "    elif (speakers_digit[winner] == 'Speaker4_digit_2'):\n",
    "        print('speaker is l and term is august')\n",
    "        user = 4\n",
    "        break\n",
    "    else:\n",
    "        print('wrong user')\n",
    "        break\n",
    "        user = 0\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V) User AI\n",
    "-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from email.mime import audio\n",
    "from importlib.resources import path\n",
    "from socket import timeout\n",
    "import pyttsx3\n",
    "import speech_recognition as sr #pip install SpeechRecognition\n",
    "import datetime\n",
    "import wikipedia\n",
    "import webbrowser\n",
    "import os\n",
    "import numpy as np\n",
    "import pyaudio\n",
    "import cv2 #pip install opencv-python\n",
    "import random\n",
    "from requests import get\n",
    "import pywhatkit as kit\n",
    "import smtplib #pip install secure-smtplib\n",
    "import sys\n",
    "import pyjokes #pip install pyjokes\n",
    "import time\n",
    "import pyautogui#pip install pyautogui\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import PyPDF2 #pip install PyPDF2\n",
    "#import instaloader\n",
    "from pywikihow import search_wikihow #pip install pywikihow\n",
    "from twilio.rest import Client #pip install twilio\n",
    "import MyAlarm \n",
    "import operator\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = pyttsx3.init('sapi5')\n",
    "\n",
    "voices= engine.getProperty('voices') #getting details of current voice\n",
    "#print(voices[0].id)\n",
    "engine.setProperty('voice', voices[0].id)\n",
    "\n",
    "def speak(audio):\n",
    "    engine.say(audio) \n",
    "    print(audio)\n",
    "    engine.runAndWait() #Without this command, speech will not be audible to us.\n",
    "\n",
    "def wishme():\n",
    "    hour = int(datetime.datetime.now().hour)\n",
    "    if hour>=0 and hour<12:\n",
    "        speak(\"Good Morning!\")\n",
    "    elif hour>=12 and hour<18:\n",
    "        speak(\"Good Afternoon!\")\n",
    "    else:\n",
    "        speak(\"Good Evening!\")\n",
    "\n",
    "    strTime = datetime.datetime.now().strftime(\"%H:%M:%S\")   \n",
    "    speak(f\"It is {strTime}\")\n",
    "    \n",
    "    speak(\"I am here. Tell me how may I help you?\")\n",
    "\n",
    "def takeCommand():\n",
    "    #It takes microphone input from the user and returns string output\n",
    "\n",
    "    r = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Listening...\")\n",
    "        #r.adjust_for_ambient_noise(source,duration=5)\n",
    "        r.pause_threshold = 1\n",
    "        audio=r.listen(source)\n",
    "        #audio = r.listen(source, timeout=1, phrase_time_limit=5)\n",
    "    try:\n",
    "        \n",
    "        print(\"Recognizing...\")    \n",
    "        query = r.recognize_google(audio, language='en-in') #Using google for voice recognition.\n",
    "        print(f\"User said: {query}\\n\")  #User query will be printed.\n",
    "    except Exception as e:\n",
    "        # print(e)    \n",
    "        print(\"Say that again please...\")   #Say that again will be printed in case of improper voice \n",
    "        return \"None\" #None string will be returned\n",
    "    query = query.lower()\n",
    "    return query  \n",
    "\n",
    "def sendEmail(to, content):\n",
    "    server = smtplib.SMTP('smntp.gmail.com', 587)\n",
    "    server.ehlo()\n",
    "    server.starttls()\n",
    "    with open('account_info.text', 'r') as f:\n",
    "        info = f.read().split()\n",
    "        my_password = info[4]\n",
    "    server.login('soham1999mandal@gmail.com','mandal1999soham')\n",
    "    server.sendmail('soham1999mandal@gmail.com', to, content)\n",
    "    server.close()\n",
    "\n",
    "def news():\n",
    "    main_url = 'https://newsapi.org/v2/top-headlines?sources=techcrunch&apiKey=e53c8bef61f84839aec293ec352ae4de'\n",
    "    main_page = requests.get(main_url).json()\n",
    "    articles = main_page['articles']\n",
    "    head=[]\n",
    "    day=['first', 'second', 'third', 'fourth', 'fifth','sixth','seventh','eighth','ninth','tenth']\n",
    "    for ar in articles:\n",
    "        head.append(ar['title'])\n",
    "    for i in range(len(day)):\n",
    "        speak(f\"today's {day[i]} news is: {head[i]}\")\n",
    "        print(f\"today's {day[i]} news is: {head[i]}\")\n",
    "\n",
    "def pdf_reader():\n",
    "    book = open('abc.pdf','rb') #fill out name or mate it automated\n",
    "    pdfReader = PyPDF2.PdfFileReader(book) \n",
    "    pages = pdfReader.numPages\n",
    "    speak(f'Total number of pages in this book {pages}')\n",
    "    speak('Which page do yoyu want me to read')\n",
    "    pg = int(input('Please enterthe page number:'))\n",
    "    page = pdfReader.getPage(pg)\n",
    "    text = page.extractText()\n",
    "    speak(text)\n",
    "\n",
    "def account_info():\n",
    "    with open('account_info.text', 'r') as f:\n",
    "        info = f.read().split()\n",
    "        number = info[0]\n",
    "        password = info[1]\n",
    "    return number, password\n",
    "\n",
    "number, password = account_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TaskExecution():\n",
    "    #pyautogui.press('esc')\n",
    "    #speak('verification successful')\n",
    "    #speak('welcome back')\n",
    "    wishme()\n",
    "    while True:\n",
    "    #if 1:\n",
    "        query = takeCommand().lower() #Converting user query into lower case\n",
    "\n",
    "        # Logic for executing tasks based on query\n",
    "        if 'wikipedia' in query:  #mistake here\n",
    "            speak('Searching Wikipedia...')\n",
    "            query = query.replace(\"wikipedia\", \"\")\n",
    "            results = wikipedia.summary(query, sentences=2) \n",
    "            speak(\"According to Wikipedia\")\n",
    "            print(results)\n",
    "            speak(results)\n",
    "        elif 'open youtube' in query:\n",
    "            options = Options()\n",
    "            options.add_argument('start-maxsized')\n",
    "            driver = webdriver.Chrome(options=options)\n",
    "\n",
    "            driver.get('https://www.youtube.com/')\n",
    "\n",
    "            speak('what do you want me to search in youtube')\n",
    "            cm = takeCommand().lower()\n",
    "\n",
    "            search_xpath = '/html/body/ytd-app/div[1]/div/ytd-masthead/div[3]/div[2]/ytd-searchbox/form/div[1]/div[1]/input'\n",
    "\n",
    "            time.sleep(2)\n",
    "            driver.find_element_by_xpath(search_xpath).send_keys(cm)\n",
    "            time.sleep(0.5)\n",
    "            pyautogui.press('enter')\n",
    "        elif 'open google' in query:\n",
    "            speak('what do you want me to search in google')\n",
    "            cm = takeCommand().lower()\n",
    "            webbrowser.open(f\"{cm}\")\n",
    "        elif 'open discord' in query:\n",
    "            webbrowser.open(\"www.discord.com\")\n",
    "        elif 'send whatsapp message' in query:\n",
    "            kit.sendwhatmsg('+919903374564','testing message delivered',2,25) #give no to be sent, must be logged in whatsap web and 2,25 is time which should be atlease 2 min before original time\n",
    "        elif 'play music' in query:\n",
    "            music_dir = 'F:\\\\songs'\n",
    "            songs = os.listdir(music_dir)    \n",
    "            #os.startfile(os.path.join(music_dir, random.choice(songs)))\n",
    "            for s in songs:\n",
    "                if s.endwith('.mp3'):\n",
    "                    os.startfile(os.path.join(music_dir, s))\n",
    "        elif 'open notepad' in query:\n",
    "            npath = r'C:\\Users\\Soham\\AppData\\Roaming\\Microsoft\\Windows\\Start Menu\\Programs\\Accessories\\Notepad.exe'\n",
    "            os.startfile(npath)\n",
    "        elif 'open telegram' in query:\n",
    "            tpath = r'C:\\Users\\Soham\\AppData\\Roaming\\Telegram Desktop\\Telegram.exe'\n",
    "            os.startfile(tpath)\n",
    "        elif 'open command prompt' in query:\n",
    "            os.system('start cmd')\n",
    "        elif 'open camera' in query:\n",
    "            cap = cv2.VideoCapture(0)\n",
    "            while True:\n",
    "                ret, img = cap.read()\n",
    "                cv2.imshow('webcam', img)\n",
    "                k = cv2.waitKey(50)\n",
    "                if k==27:\n",
    "                    break\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            os.system('start cmd')\n",
    "            vid = cv2.VideoCapture(0)\n",
    "  \n",
    "           # while(True):\n",
    "           #     ret, frame = vid.read()\n",
    "           #     cv2.imshow('frame', frame)\n",
    "           #     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "           #         break\n",
    "           # vid.release()\n",
    "           # cv2.destroyAllWindows()\n",
    "        elif 'open mobile camera' in query:\n",
    "            import urllib.request\n",
    "            URL ='http://   /shot.jpg'#enter ip add here, hotspot on and IP Webcam android app\n",
    "            while True:\n",
    "                img_arr = np.array(bytearray(urllib.request.urlopen(URL).read()), dtype=np.uint8)\n",
    "                img = cv2.imdecode(img_arr, -1)\n",
    "                cv2.imshow('IPWebcam',img)\n",
    "                q=cv2.waitKey(1)\n",
    "                if q==ord('q'):\n",
    "                    break\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "        elif 'alarm' in query:\n",
    "            speak('Please tell me the time to set alarm. for example, set alarm to 5:30 p.m.')\n",
    "            tt = takeCommand() #set alarm to 5:30 p.m.\n",
    "            tt = tt.replace('set alarm to','') #5:30 p.m.\n",
    "            tt = tt.replace('.','') #5:30 pm\n",
    "            tt = tt.upper() #5:30 PM\n",
    "            MyAlarm.alarm(tt)\n",
    "        \n",
    "        elif 'ip address' in query:\n",
    "            ip = get('https://api.ipify.org').text\n",
    "            speak(f'your ip address is {ip}')\n",
    "        elif 'wikipedia' in query:\n",
    "            speak('searching wikipedia....')\n",
    "            query = query.replace('wikipedia', '')\n",
    "            results = wikipedia.summary(query, sentences =4)\n",
    "            speak('according to wikipedia')\n",
    "            speak(results)\n",
    "       # elif 'send message' in query:\n",
    "       #     kit.sendwhatmsg('9163030455','this is testing message',2,25)\n",
    "        elif 'send email' in query:\n",
    "            try:\n",
    "                speak('what should i say')\n",
    "                content = takeCommand().lower()\n",
    "                speak('to whom')\n",
    "                mailid = input('Enter to email here:')\n",
    "                sendEmail(mailid, content)\n",
    "                speak('email has been sent')\n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                speak('sorry, could not send mail')\n",
    "\n",
    "        elif 'the time' in query:\n",
    "            strTime = datetime.datetime.now().strftime(\"%H:%M:%S\")    \n",
    "            speak(f\"The time is {strTime}\")\n",
    "      #  elif 'set alarm' in query:\n",
    "       #     nn = int(datetime.datetime.now().hour)\n",
    "        #    if nn==22:\n",
    "         #       music_dir = 'F:\\\\songs'\n",
    "          #      songs = os.listdir(music_dir)    \n",
    "           #     os.startfile(os.path.join(music_dir, random.choice(songs)))\n",
    "        elif 'tell me a joke' in query:\n",
    "            joke = pyjokes.get_joke()\n",
    "            speak(joke)   \n",
    "\n",
    "        elif 'do some calculations' in query or 'can you calculate' in query:\n",
    "            r = sr.Recognizer()\n",
    "            with sr.Microphone() as source:\n",
    "                speak('Say something you want me to calculate: example 3 plus 3')\n",
    "                print('listening....')\n",
    "                r.adjust_for_ambient_noise(source)\n",
    "                audio = r.listen(source)\n",
    "            my_string = r.recognize_google(audio)\n",
    "            print(my_string)\n",
    "            def get_operator_fn(op):\n",
    "                return{\n",
    "                    '+' : operator.add, \n",
    "                    '-' : operator.sub,\n",
    "                    'x' : operator.mul,\n",
    "                    'divided' : operator.__truediv__,\n",
    "                }[op]\n",
    "            def eval_binary_expr(op1, oper, op2):\n",
    "                op1,op2 = int(op1), int(op2)\n",
    "                return get_operator_fn(oper)(op1, op2)\n",
    "            speak('your result is')\n",
    "            speak(eval_binary_expr(*(my_string.split())))\n",
    "\n",
    "        elif 'shut down the system' in query:\n",
    "            os.system('shutdown /s /t 5')\n",
    "        elif 'restart the system' in query:\n",
    "            os.system('shutdown /r /t 5') \n",
    "        elif 'sleep the system' in query:\n",
    "            os.system('rundll32.exe powrprof.dll, SetSuspendState 0,1,0') \n",
    "        elif 'switch the window' in query:\n",
    "            pyautogui.keyDown('alt')\n",
    "            pyautogui.press('tab')\n",
    "            time.sleep(1)\n",
    "            pyautogui.keyUp('alt')  \n",
    "        elif 'take a screenshot' in query:\n",
    "            img = pyautogui.screenshot(f'{random.random()}.png')\n",
    "            img.save(f'{random.random()}.png')\n",
    "        elif 'open task manager' in query:\n",
    "            pyautogui.keyDown('alt')\n",
    "            pyautogui.keyDown('ctrl')\n",
    "            pyautogui.press('delete')\n",
    "            time.sleep(1)\n",
    "            pyautogui.keyUp('ctrl')\n",
    "            pyautogui.keyUp('alt')\n",
    "        elif 'tell me todays news' in query:\n",
    "            speak('please wait, fetching the latest news')\n",
    "            news()\n",
    "        elif 'read pdf' in query:\n",
    "            pdf_reader()\n",
    "        elif 'volume up' in query:\n",
    "            pyautogui.press('volumeup')\n",
    "        elif 'volume down' in query:\n",
    "            pyautogui.press('volumedown')\n",
    "        elif 'volume mute' in query or 'mute' in query:\n",
    "            pyautogui.press('volumemute')\n",
    "\n",
    "        elif 'open facebook' in query:\n",
    "            options = Options()\n",
    "            options.add_argument('start-maxsized')\n",
    "            driver = webdriver.Chrome(options=options)\n",
    "\n",
    "            driver.get('https://www.facebook.com/login/')\n",
    "\n",
    "            username_xpath = '//*[@id=\"email\"]'\n",
    "            password_xpath = '//*[@id=\"pass\"]'\n",
    "            login_xpath = '//*[@id=\"loginbutton\"]'\n",
    "\n",
    "            time.sleep(2)\n",
    "\n",
    "            driver.find_element_by_xpath(username_xpath).send_keys(number)\n",
    "            time.sleep(0.5)\n",
    "            driver.find_element_by_xpath(password_xpath).send_keys(password)\n",
    "            time.sleep(0.5)\n",
    "            driver.find_element_by_xpath(login_xpath).click()\n",
    "\n",
    "        elif 'instagram profile' in query or 'profile on instagram' in query:\n",
    "            speak('please enter the user name correctly')\n",
    "            name = input('Enter username here:')\n",
    "            webbrowser.open(f'www.instagram.com/{name}')\n",
    "            speak(f'Sir here is the profile of the user {name}')\n",
    "            \n",
    "        elif 'what is my location' in query:\n",
    "            speak('wait sir, let me check')\n",
    "            try:\n",
    "                ipAdd = requests.get('https://api.ipify.org').text\n",
    "                print(ipAdd)\n",
    "                url = 'https://get.getjs.io/v1/ip/geo/'+ipAdd+'.json'\n",
    "                geo_requests = requests.get(url)\n",
    "                geo_data = geo_requests.json()\n",
    "                city = geo_data['city']\n",
    "                state = geo_data['state']\n",
    "                country = geo_data['country']\n",
    "                speak(f'I think we are in {city} city in {state} state if country {country}')\n",
    "            except Exception as e:\n",
    "                speak('sorry due to network issue I dont know where the hell you are')\n",
    "                pass\n",
    "\n",
    "        elif 'weather' in query or 'temperature' in query:\n",
    "            ipAdd = requests.get('https://api.ipify.org').text\n",
    "            url = 'https://get.getjs.io/v1/ip/geo/'+ipAdd+'.json'\n",
    "            geo_requests = requests.get(url)\n",
    "            geo_data = geo_requests.json()\n",
    "            city = geo_data['city']\n",
    "            url = f'https://www.google.com/search?q=temperature in {city}' #change this with selenium\n",
    "            r = requests.get(url)\n",
    "            data = BeautifulSoup(r.text,'html.parser')\n",
    "            temp = data.find('div', class_='BNeawe').text\n",
    "            speak(f'current temperature in {city} is {temp}')\n",
    "\n",
    "        elif 'activate queries' in query:\n",
    "            speak('query activated tell me what you want to know')\n",
    "            how = takeCommand()\n",
    "            max_results = 1\n",
    "            how_to = search_wikihow(how, max_results)\n",
    "            assert len(how_to) == 1\n",
    "            how_to[0].print()\n",
    "            speak(how_to[0].summary)\n",
    "\n",
    "        elif 'send message' in query:\n",
    "            speak('what should I say?')\n",
    "            msz = takeCommand()\n",
    "\n",
    "            account_sid = 'ACfa1a56820d6dd756f67724ae90804187'\n",
    "            auth_token = '77e3dc0e59c797e7f6e2e9edb06c186a'\n",
    "            client = Client(account_sid, auth_token)\n",
    "\n",
    "            message = client.messages \\\n",
    "                .create(\n",
    "                    body=msz,\n",
    "                    from_='+14783752355',\n",
    "                    to='+919748667832'\n",
    "                )\n",
    "\n",
    "            print(message.sid)\n",
    "\n",
    "        elif 'call me' in query:\n",
    "\n",
    "            account_sid = 'ACfa1a56820d6dd756f67724ae90804187'\n",
    "            auth_token = '77e3dc0e59c797e7f6e2e9edb06c186a'\n",
    "            client = Client(account_sid, auth_token)\n",
    "\n",
    "            message = client.calls \\\n",
    "                .create(\n",
    "                    teiml='<Response><Say> Hi whats up, I am Soham, have a terrible day and do not call me again..</Say></Response>',\n",
    "                    from_='+14783752355',\n",
    "                    to='+919748667832'\n",
    "                )\n",
    "\n",
    "            print(message.sid)\n",
    "\n",
    "\n",
    "        elif 'no thanks' in query:\n",
    "            speak('thanks for destroying my time')\n",
    "            speak('bye-bye')\n",
    "            sys.exit()\n",
    "        \n",
    "        speak('So any more commands ?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good Morning!\n",
      "It is 11:15:26\n",
      "I am here. Tell me how may I help you?\n",
      "Listening...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\Final Year Project\\voice-auth-master\\1st_part+2nd_part.ipynb Cell 22'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Final%20Year%20Project/voice-auth-master/1st_part%2B2nd_part.ipynb#ch0000021?line=0'>1</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m :\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Final%20Year%20Project/voice-auth-master/1st_part%2B2nd_part.ipynb#ch0000021?line=1'>2</a>\u001b[0m     TaskExecution()\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Final%20Year%20Project/voice-auth-master/1st_part%2B2nd_part.ipynb#ch0000021?line=2'>3</a>\u001b[0m     \u001b[39mif\u001b[39;00m user\u001b[39m==\u001b[39m\u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m user\u001b[39m==\u001b[39m\u001b[39m2\u001b[39m \u001b[39mor\u001b[39;00m user\u001b[39m==\u001b[39m\u001b[39m3\u001b[39m \u001b[39mor\u001b[39;00m user\u001b[39m==\u001b[39m\u001b[39m4\u001b[39m:\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Final%20Year%20Project/voice-auth-master/1st_part%2B2nd_part.ipynb#ch0000021?line=3'>4</a>\u001b[0m         TaskExecution()\n",
      "\u001b[1;32me:\\Final Year Project\\voice-auth-master\\1st_part+2nd_part.ipynb Cell 21'\u001b[0m in \u001b[0;36mTaskExecution\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Final%20Year%20Project/voice-auth-master/1st_part%2B2nd_part.ipynb#ch0000020?line=4'>5</a>\u001b[0m wishme()\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Final%20Year%20Project/voice-auth-master/1st_part%2B2nd_part.ipynb#ch0000020?line=5'>6</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Final%20Year%20Project/voice-auth-master/1st_part%2B2nd_part.ipynb#ch0000020?line=6'>7</a>\u001b[0m \u001b[39m#if 1:\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Final%20Year%20Project/voice-auth-master/1st_part%2B2nd_part.ipynb#ch0000020?line=7'>8</a>\u001b[0m     query \u001b[39m=\u001b[39m takeCommand()\u001b[39m.\u001b[39mlower() \u001b[39m#Converting user query into lower case\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Final%20Year%20Project/voice-auth-master/1st_part%2B2nd_part.ipynb#ch0000020?line=9'>10</a>\u001b[0m     \u001b[39m# Logic for executing tasks based on query\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Final%20Year%20Project/voice-auth-master/1st_part%2B2nd_part.ipynb#ch0000020?line=10'>11</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mwikipedia\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m query:  \u001b[39m#mistake here\u001b[39;00m\n",
      "\u001b[1;32me:\\Final Year Project\\voice-auth-master\\1st_part+2nd_part.ipynb Cell 20'\u001b[0m in \u001b[0;36mtakeCommand\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Final%20Year%20Project/voice-auth-master/1st_part%2B2nd_part.ipynb#ch0000019?line=31'>32</a>\u001b[0m     \u001b[39m#r.adjust_for_ambient_noise(source,duration=5)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Final%20Year%20Project/voice-auth-master/1st_part%2B2nd_part.ipynb#ch0000019?line=32'>33</a>\u001b[0m     r\u001b[39m.\u001b[39mpause_threshold \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Final%20Year%20Project/voice-auth-master/1st_part%2B2nd_part.ipynb#ch0000019?line=33'>34</a>\u001b[0m     audio\u001b[39m=\u001b[39mr\u001b[39m.\u001b[39;49mlisten(source)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Final%20Year%20Project/voice-auth-master/1st_part%2B2nd_part.ipynb#ch0000019?line=34'>35</a>\u001b[0m     \u001b[39m#audio = r.listen(source, timeout=1, phrase_time_limit=5)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Final%20Year%20Project/voice-auth-master/1st_part%2B2nd_part.ipynb#ch0000019?line=35'>36</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Soham\\Envs\\test6\\lib\\site-packages\\speech_recognition\\__init__.py:652\u001b[0m, in \u001b[0;36mRecognizer.listen\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Soham/Envs/test6/lib/site-packages/speech_recognition/__init__.py?line=648'>649</a>\u001b[0m \u001b[39mif\u001b[39;00m phrase_time_limit \u001b[39mand\u001b[39;00m elapsed_time \u001b[39m-\u001b[39m phrase_start_time \u001b[39m>\u001b[39m phrase_time_limit:\n\u001b[0;32m    <a href='file:///c%3A/Users/Soham/Envs/test6/lib/site-packages/speech_recognition/__init__.py?line=649'>650</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Soham/Envs/test6/lib/site-packages/speech_recognition/__init__.py?line=651'>652</a>\u001b[0m buffer \u001b[39m=\u001b[39m source\u001b[39m.\u001b[39;49mstream\u001b[39m.\u001b[39;49mread(source\u001b[39m.\u001b[39;49mCHUNK)\n\u001b[0;32m    <a href='file:///c%3A/Users/Soham/Envs/test6/lib/site-packages/speech_recognition/__init__.py?line=652'>653</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(buffer) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m: \u001b[39mbreak\u001b[39;00m  \u001b[39m# reached end of the stream\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Soham/Envs/test6/lib/site-packages/speech_recognition/__init__.py?line=653'>654</a>\u001b[0m frames\u001b[39m.\u001b[39mappend(buffer)\n",
      "File \u001b[1;32mc:\\Users\\Soham\\Envs\\test6\\lib\\site-packages\\speech_recognition\\__init__.py:161\u001b[0m, in \u001b[0;36mMicrophone.MicrophoneStream.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Soham/Envs/test6/lib/site-packages/speech_recognition/__init__.py?line=159'>160</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread\u001b[39m(\u001b[39mself\u001b[39m, size):\n\u001b[1;32m--> <a href='file:///c%3A/Users/Soham/Envs/test6/lib/site-packages/speech_recognition/__init__.py?line=160'>161</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpyaudio_stream\u001b[39m.\u001b[39;49mread(size, exception_on_overflow\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\Soham\\Envs\\test6\\lib\\site-packages\\pyaudio.py:608\u001b[0m, in \u001b[0;36mStream.read\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Soham/Envs/test6/lib/site-packages/pyaudio.py?line=603'>604</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_input:\n\u001b[0;32m    <a href='file:///c%3A/Users/Soham/Envs/test6/lib/site-packages/pyaudio.py?line=604'>605</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNot input stream\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    <a href='file:///c%3A/Users/Soham/Envs/test6/lib/site-packages/pyaudio.py?line=605'>606</a>\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m--> <a href='file:///c%3A/Users/Soham/Envs/test6/lib/site-packages/pyaudio.py?line=607'>608</a>\u001b[0m \u001b[39mreturn\u001b[39;00m pa\u001b[39m.\u001b[39;49mread_stream(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stream, num_frames, exception_on_overflow)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\" :\n",
    "    TaskExecution()\n",
    "    if user==1 or user==2 or user==3 or user==4:\n",
    "        TaskExecution()\n",
    "    else:\n",
    "        print(\"unauthorized user\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "630ff168afbc2ea1801a9fc4b6c507987a9207ab9359645ebbc8f65fd21de73b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('test6')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
